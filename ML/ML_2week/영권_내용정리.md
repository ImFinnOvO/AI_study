# 데이터 핸들링 - 판다스 

1. 판다스의 핵심 객체 DataFrame
2. 기본적인 데이터 핸들링
3. Dataframe과 리스트, 딕셔너리, ndarray 상호 변환
4. 데이터 삭제
5. index객체
6. Dataframe 인덱싱
7. DataFrame, Series의 정렬
8. 결손 데이터 처리하기
9. apply lambda 식으로 데이터 가공


## 1) 판다스의 핵심 객체 DataFrame
---

Dataframe은 여러 개의 행과 열로 이뤄진 2차원 데이터를 담는 데이터 구조체이다.

Series는 column을 하나만 가지는 데이터구조체이다.

Series와 Dataframe은 모두 Index를 key값으로 가지고 있다.

## 2) 기본적인 데이터 핸들링

---
* 판다스 임포트하기
``` python
import pandas as pd
```

* read_csv() 사용하기 

``` python
df = pd.read_csv('csv파일이 저장된 경로와 파일')
```

* head() 사용하기

head()는 상위 5개의 row를 출력한다.

괄호안에 인자로 5이하의 숫자를 넣어주면 그만큼의 row를 출력 할 수 있다.

``` python
df.head(3) 
```

* shape 사용하기

Dataframe.shape 는 행과 열의 개수를 튜플 형태로 반환

``` python
print('Dataframe크기: ', df.shape)
```

* info() 사용하기 

Dataframe.info() 는 행과 열의 개수, 칼럼별 데이터 타입과 칼럼별 Null값을 가지지 않는 데이터 개수와 칼럼별 데이터 타입을 나타낸다.

``` python
df.info()
```

* describe() 사용하기

Dataframe.describe() 는 대략적인 데이터 분포도를 확인할 수 있다

``` python
df.describe()
```

* value_counts() 사용하기

Dataframe.value_counts() 는 많은 건수 순서로 정렬되어 값을 반환한다.

``` python
df['Pclasss'].value_counts()
```

## 3) Dataframe과 리스트, 딕셔너리, ndarray 상호 변환

---
2차원 리스트, 2차원 ndarray, series, 사전으로 Dataframe 만들기 가능.

사전으로 Dataframe을 만들 때, Key 값 = columns 사전의 value 값 = column에 해당하는 리스트, ndarray, series...

리스트가 담긴 사전 뿐만 아니라, 사전이 담긴 리스트로도 Dataframe을 만들 수 있다.
``` python
my_list =[
    {'name':'abc','english_score':90,'math_score':80},
    {'name':'def','english_score':80,'math_score':100}]
df=pd.DataFrame(my_list)
# 출력해보면 입력해준 column의 순서가 다를 수 있음. set 또는 dictionary는 순서가 없는 자료구조이기 때문에 그렇다.
#  파이썬 3.7이상에서는 사전의 입력순서가 보장된다고 함.
```


## 4) 데이터 삭제

---

drop() 메서드를 사용한다.

인자의 inplace의 디폴트값은 False이다. 특정 데이터를 삭제한 dataframe을 새롭게 만들어 반환한다는 것이다. 

이 경우 원본 dataframe은 유지된다

inplace = True 인 경우는, 원본 데이터를 변환하고, 반환값은 없다.

``` python
# row를 삭제하고 싶은 경우
df=df.drop('삭제하고싶은row명', axis = 0, inplace = False)

# column을 삭제하고 싶은 경우, 원본데이터를 변환하고싶은 경우
df.drop('삭제하고싶은 column명', axis = 1, inplace = True)
```

## 5) index객체

---

Dataframe이나 Series에서 Index객체만 추출하고 싶다면, Dataframe.index 또는 Series.index

* reset_index()

Dataframe.reset_index()는 새롭게 연속 숫자 형으로 인덱스를 설정한다.

기존 인덱스는 'index'라는 새로운 칼럼명으로 추가됨.
``` python
reset_df = df.reset_index(inplace = False)
```

## 6) Dataframe 인덱싱

---

|이름으로인덱싱|기본형태|단축형태|
|---|---|---|
|하나의 row 이름|df.loc[ 'row4' ]||
|row 이름의 리스트| df.loc[[ 'row4' , 'row5' ]]||
|row 이름의 리스트 슬라이싱| df.loc[ 'row2' : 'row6' ]|df[ 'row2' : 'row6' ]|
|하나의 column이름|df.loc[: , 'col2' ]|df[ 'col2' ]|
|column 이름의 리스트|df.loc[: , ['col2' , 'col3']]|df[['col2', 'col3']]
|column 이름의 리스트 슬라이싱|df.loc[: , 'col2' : 'col5']||

|위치로인덱싱|기본형태|단축형태|
|---|---|---|
|하나의 row 위치|df.iloc[ 8 ]||
|row 위치의 리스트| df.iloc[[ 4, 5, 3 ]]||
|row 위치의 리스트 슬라이싱| df.iloc[ 2 : 5 ]|df[ 2 : 5 ]|
|하나의 column위치|df.iloc[: , 3 ]||
|column 위치의 리스트|df.iloc[: , [3, 5, 6]]|
|column 위치의 리스트 슬라이싱|df.iloc[: , 3 : 7]||

불린인덱싱 또한 사용할 수 있다.

## 7) DataFrame, Series의 정렬

---

* 정렬을 위해서는 sort_values() 메서드를 사용.

인자로는 by=칼럼지정 (해당 칼럼으로 정렬을 수행) , ascending=True(디폴트)/False (오름차순/내림차순) , inplace = True/False 이다.



``` python
df_sorted = df.sort_values(by=['Name'])
```

* groupby() 

같은 값을 하나로 묶어 통계 또는 집계 결과를 얻기 위해 사용하는 것이다.

groupby메서드 뒤에 aggregation함수를 추가로 붙여 사용하는 것이 일반적인 것 같음.

agg() 인자에 함수 여러개를 넣을 수 있음

``` python
df_groupby = df.groupby(['Pclass']).mean()    #이런식으로 사용
```

## 8) 결손 데이터 처리하기
 ---

 결손 데이터란 칼럼에 값이 없는, 즉 Null값을 의미하며, 이는 넘파이의 NaN으로 표시,

 머신러닝 알고리즘에는 이 값을 처리하지 않으므로 다른 값으로 대체해야 한다. 
 
 또한 NaN값은 평균, 총합 등의 연산 시 제외가 됨.

 * isna()

 Dataframe.isna() 는 NaN 이라면 True를, 아니라면 False로 나타낸다

 결손 데이터의 개수는 Dataframe.isna().sum()으로 구할 수 있다. True는 1, False는 0 으로 처리되기 때문.

* fillna()로 결손 데이터 처리

Dataframe[ '대체할 데이터가 속한 column명' ].fillna( '대체할데이터값' )

inplace 인자를 포함하고 있음.

## 9) apply lambda 식으로 데이터 가공
---

람다식을 활용하여 Dataframe을 다룰 수 있다.


``` python
titainc_df['Name_len'] = titanic_df['Name'].apply(lambda x : len(x))
```

# 사이킷런(scikit - learn)

* sklearn.datasets 내의 모듈은 사이킷런에서 학습용으로 제공하는 데이터셋이 들어있음.

* sklearn.metrics 내에는 평균제곱오차를 구하는 함수, 정확도측정 등 

예)

``` python
from sklearn.metrics import mean_squared_error    #평균제곱오차를 구하는 함수

...

y_test_prediction = model.predict(X_test)    #X_test셋을 이용하여 예측한 값

```

* sklearn.tree 내의 모듈은 트리 기반 머신러닝 알고리즘을 구현한 클래스들이 들어있음.

예)

``` python
from sklearn.tree import DecisionTreeClassifier 

...

dt_clf = DecisionTreeClassifier(random_state=11)    #사이킷런의 의사 결정 트리 클래스
dt_clf.fit(X_train , y_train)    #학습 수행

pred = dt_clf.predict(X_test)    #테스트셋으로 예측을 수행
print('예측 정확도 : {0:.4f}'.format(accuracy_score(y_test,pred)))    #예측값과 실제 목표 테스트셋을 비교하여 정확도 출력
```

sklearn.model_selection 내의 모듈은 학습데이터, 검증 데이터, 예측 데이터로 데이터를 분리하는 등 다양한 모듈이 들어있음

예)

``` python 
from sklearn.model_selection import train_test_split
#train_test_split()은 데이터셋을 테스트셋과 트레이닝셋으로 구분해주는 역할

...

X_train , X_test , y_train , y_test = train_test_split(입력변수, 목표변수, test_size = 0.2 , random_state = 5)
# test_size를 0.2로 설정하면 전체 데이터중 2할만 골라 테스트셋으로, 나머지 8할은 트레이닝 셋으로 한다. 
# random_state는 그 테스트셋을 어떻게 정하는지 고르는 파라미터임, 옵셔널 파라미터이기 때문에 안넣어줘도 됨. 안넣을 경우 테스트셋이 랜덤하게 뽑히지 않음.
```
