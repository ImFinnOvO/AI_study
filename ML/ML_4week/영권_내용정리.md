# 평가

회귀에서의 성능 평가 지표(Evaluation Metric)는 평균제곱오차 이런거...

분류에서의 성능 평가 지표로는,
* 정확도(Accuracy)

* 오차 행렬(Confusion Matrix)

* 정밀도(Precision)

* 재현율(Recall)

* F1 스코어

* ROC AUC

## 정확도(Accuracy)

---
이진 분류의 경우 데이터의 구성에 따라 ML모델의 성능을 왜곡할 수 있기 때문에 정확도 수치 하나만 가지고 성능을 평가하지 않는다.


__정확도__(Accuracy) = __예측결과가 동일한 데이터 건수__ / __전체 예측 건수__


## BaseEstimator 란?
---
사이킷런은 BaseEstimator를 상속받으면 커스텀할수있는 분류,회귀 알고리즘을 만들 수 있음.

## 오차 행렬(Confusion matrix)

---
TN은 예측값을 Negative값 0으로 예측헀고 실제 값 역시 Nagative값 0

FP은 예측값을 Positive값 1로 예측했는데 실제 값은 Negative값 0

FN은 예측값을 Negative값 0으로 예측했는데 실제 값은 Positive값 1

TP는 예측값을 Positive값 1로 예측했고 실제 값 역시 Positive값 1

이 네가지 값을 조합해 분류 알고리즘 성능을 측정할 수 있는 주요 지표인 정확도(Accuracy)), 정밀도(Precision), 재현을(Recall) 값을 알 수 있음.

* __정확도__ = (TN + TP)/(TN + FP + FN + TP)

* __정밀도__ = TP/(FP + TP)

* __재현율__ = TP/(FN + TP)

재현율이 중요한 지표인 경우는 실제Positive 양성인 데이터 예측을 Negative로 잘못 판단하게 되면 큰 영향이 발생하는 경우

정밀도가 중요한 지표인 경우는 실제Negative 음성인 데이터 예측을 Positive 양성으로 잘못 판단하게 되면 큰 영향이 발생하는 경우

사이킷런에서는 정밀도 계산을 위해 __precision_score()__ 를, 재현율 계산을 위해 __recall_score()__ 사용

``` python
from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score

precision = precision_score(y_test, pred)
recall = recall_score(y_test, pred)
confusion = confusion_matrix(y_test, pred)
accuracy_score(y_test, pred)
```

정밀도 혹은 재현율이 특별히 강조되어야 할 경우 분류의 __결정 임곗값__ (Threshold)을 조정해 정밀도 또는 재현율의  수치를 높일 수 있음.

하지만 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의 수치가 떨어지기 쉬움.

이것을 __정밀도/재현율의 트레이드오프__ (Trade_off)라고 함.

사이킷런은 개별 데이터별로 예측 확률을 반환하는 predict_proba() 사용.

predict_proba()는 학습이 완료된 사이킷런 분류 객체에서 호출이 가능하며 테스트 피처 데이터셋을 파라미터로 입력해주면 개별 예측 확률을 반환함.

Binarizer클래스의 __fit_transform()__ 

``` python
from sklearn.preprocessing import Binarizer

X= [[ 1, -1, 2],
    [2, 0, 0]]
binarizer = Binarizer(threshold = 1.1)    #결정 임곗값을 1.1로 변경
print(binarizer.fit_transform(X))
```

임곗값이 낮아질수록 재현율 증가.

사이킷런의 __precision_recall_curve()__ 

``` python
from sklearn.metrics import precision_recall_curve

pred_proba_class1 = Ir_clf.predict_proba(X_test)[:,1]
precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)
```

## F1 스코어

---
정밀도와 재현율을 결합한 지표, F1스코어는 정밀도와 재현율이 어느 한쪽으로 치우치지않는  수치를 나타낼 때 상대적으로 높은 값을 가짐.

$$ F1 = 2/(1/recall+1/precision) = 2 * precision * recall/(precision + recall) $$

사이킷런은 F1스코어를 구하기 위해 f1_score() 제공.

``` python
from sklearn.metrics import f1_score

f1 = f1_score(y_test,pred)
```

## ROC곡선과 AUC

---

ROC곡선 (Receiver Operation Characteristic Curve) 과 이에 기반한 AUC스코어는 이진 분류의 예측성능 측정에서 중요하게 사용되는 지표.
ROC곡선은 FPP(False Positive Rate)이 변할 때 TPR(True Positive Rate:재현율)가 어떻게 변하는지를 나타내는 곡선임.

사이킷런은 ROC곡선을 구하기 위해 roc_curve() 제공.
사용법은 precision_recall_curve() 와 유사. 반환값이 FPR, TPR, 임곗값으로 차이만 있을 뿐임.

``` python
from sklearn.metrics import roc_curve

# 레이블 값이 1 일때의 예측 확률을 추출
pred_proba_class1 = Ir_clf.predict_proba(X_test)[:,1]

fpr, tpr, thresholds = roc_curve(y_test,pred_proba_class1)

```

일반적으로 ROC곡선 자체는 FPR과 TPR의 변화값을 보는데 이용하며 분류의  성능 지표로 사용되는 것은 ROC곡선 면적에 기반한 AUC값으로 결정.
AUC(Area Under Curve) 값은 ROC곡선 밑의 면적을 구한 것으로서 일반적으로 1에 가까울수록 좋은 수치임.

``` python
from sklearn.metrics import roc_auc_score

pred_proba = Ir_clf.predict_proba(X_test)[:,1]
roc_score = roc_auc_score(y_test, pred_proba)
```

# 분류

지도학습은 레이블(Label)즉 명시적인 정답이 있는 데이터가 주어진 상태에서 학습하는 머신러닝 방식.

지도학습의 대표적인 유형인 분류(Classification)는 학습 데이터로 주어진 데이터의 피처와 레이블값(결정 값, 클래스 값)을 머신러닝 알고리즘으로 학습해 모델을 생성하고, 이렇게 생성된 모델에 새로운 데이터가 주어졌을때 레이블 값을 예측하는것임.

* 데이터 균일도에 따른 규칙 기반의 __결정트리__(Decision Tree)(앙상블의 기반 알고리즘)
* 서로다른(또는 같은) 머신러닝 알고리즘을 결합한 __앙상블__(Ensemble)
* 독립변수와 종속변수의 선형 관계성에 기반한 __로지스틱 회귀__(Logistic Regression)

## 결정 트리(Decision Tree)

---

결정 트리란 머신러닝 알고리즘중 직관적으로 이해하기 쉬운 알고리즘.

__단점__ : 예측 성능을 향상시키기위해 복잡한 규칙 구조를 가져야 하며, 이로인한 과적합(overfitting)이 발생해 예측 성능이 떨어질 수 있는 단점.

데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리(Tree)기반의 분류 규칙을 만드는 것임.

* 규칙노드(Decision Node) : 규칙 조건

* 리프노드(Leaf Node) : 결정된 클래스 값, 더이상 자식 노드가 없는 노드

정보의 균일도를 측정하는 대표적인 방법은 엔트로피를 이용한 정보 이득(Information Gain)지수와 지니 계수

* 정보 이득 : 정보이득 지수는 1에서 엔트로피를 뺀 값임. 결정 트리는 정보이득이 높은 속성을 기준으로 분할

* 지니 계수 : 0이 평등한 상태, 1로 갈수록 불평등한 상태임. 

### 결정 트리 모델의 시각화 (Graphviz패키지 사용)

``` python
import graphviz
from sklearn.tree import export_graphviz

export_graphviz(결정트리 클래스, out_file='파일명',class_names = iris_data.target_names,/
    feature_names=iris_data.feature_names, impurity=True, filled= True)

with open('파일명') as f:
    dot_graph = f.read()
graphviz.Source(dot_graph)
```
박스 색이 연하면 불확실성이 높음